"""
Syst√®me de backup LLM unifi√© : OpenAI GPT-4o + Claude Sonnet 4
Utilis√© partout dans l'application pour avoir un fallback robuste
"""
import os
import logging
import json
from typing import Dict, Any, Optional, List
from pathlib import Path
from dotenv import load_dotenv

# Charger les variables d'environnement
ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# Configuration des cl√©s API
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
CLAUDE_API_KEY = os.environ.get('CLAUDE_API_KEY')

# Imports des biblioth√®ques
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    OpenAI = None

try:
    from emergentintegrations.llm.chat import LlmChat, UserMessage
    CLAUDE_AVAILABLE = True
except ImportError:
    CLAUDE_AVAILABLE = False
    LlmChat = None
    UserMessage = None

print(f"üîß LLM Backup System Initialized:")
print(f"   - OpenAI GPT-4o: {'‚úÖ' if OPENAI_AVAILABLE and OPENAI_API_KEY else '‚ùå'}")
print(f"   - Claude Sonnet 4: {'‚úÖ' if CLAUDE_AVAILABLE and CLAUDE_API_KEY else '‚ùå'}")


class LLMBackupSystem:
    """Syst√®me de backup LLM avec OpenAI + Claude et s√©lection intelligente selon objectifs"""
    
    def __init__(self):
        self.openai_client = None
        self.claude_chat = None
        
        # Initialiser OpenAI si disponible
        if OPENAI_AVAILABLE and OPENAI_API_KEY:
            try:
                self.openai_client = OpenAI(api_key=OPENAI_API_KEY)
                print("‚úÖ OpenAI GPT-4o client initialized")
            except Exception as e:
                print(f"‚ùå OpenAI initialization error: {e}")
        
        # Initialiser Claude si disponible
        if CLAUDE_AVAILABLE and CLAUDE_API_KEY:
            try:
                self.claude_chat = LlmChat(
                    api_key=CLAUDE_API_KEY,
                    session_id="backup-system",
                    system_message="You are Claude, a helpful AI assistant. You will receive prompts that were originally designed for GPT-4o. Please provide equivalent quality responses."
                ).with_model("anthropic", "claude-4-sonnet-20250514")
                print("‚úÖ Claude Sonnet 4 client initialized")
            except Exception as e:
                print(f"‚ùå Claude initialization error: {e}")
    
    def select_primary_llm(
        self,
        business_objective: str = "equilibre",
        brand_tone: str = "professionnel", 
        platform: str = "instagram"
    ) -> tuple:
        """
        S√©lectionne le LLM primaire et backup selon la strat√©gie business
        
        Args:
            business_objective: "conversion", "communaute", "equilibre" 
            brand_tone: ton de marque (si "storytelling" force Claude primary)
            platform: "instagram", "facebook", "linkedin"
            
        Returns:
            tuple: (primary_llm, backup_llm) o√π les valeurs sont "openai" ou "claude"
        """
        
        print(f"üß† LLM Selection - Objective: {business_objective}, Tone: {brand_tone}, Platform: {platform}")
        
        # R√®gle 1: Si storytelling ‚Üí TOUJOURS Claude primary
        if brand_tone == "storytelling":
            print("üìñ Storytelling detected ‚Üí Claude PRIMARY, OpenAI backup")
            return ("claude", "openai")
        
        # R√®gle 2: Objectif conversion ‚Üí OpenAI primary
        if business_objective == "conversion":
            print("üí∞ Conversion objective ‚Üí OpenAI PRIMARY, Claude backup")
            return ("openai", "claude")
        
        # R√®gle 3: Objectif communaut√© ‚Üí Claude primary  
        if business_objective == "communaute":
            print("üë• Community objective ‚Üí Claude PRIMARY, OpenAI backup")
            return ("claude", "openai")
        
        # R√®gle 4: √âquilibr√© ‚Üí Logique par plateforme
        if business_objective == "equilibre":
            if platform.lower() == "instagram":
                print("üì∏ Instagram + Equilibr√© ‚Üí OpenAI PRIMARY, Claude backup")
                return ("openai", "claude")
            elif platform.lower() in ["facebook", "linkedin"]:
                print(f"üîó {platform.title()} + Equilibr√© ‚Üí Claude PRIMARY, OpenAI backup")
                return ("claude", "openai")
        
        # D√©faut: OpenAI primary
        print("üîÑ Default selection ‚Üí OpenAI PRIMARY, Claude backup")
        return ("openai", "claude")
    
    async def generate_completion_with_strategy(
        self,
        messages: List[Dict[str, str]],
        business_objective: str = "equilibre",
        brand_tone: str = "professionnel",
        platform: str = "instagram",
        model: str = "gpt-4o",
        temperature: float = 0.7,
        max_tokens: int = 2000,
        system_message: Optional[str] = None
    ) -> str:
        """
        G√©n√®re une completion avec s√©lection intelligente LLM selon la strat√©gie business
        """
        
        # S√©lectionner les LLM selon la strat√©gie
        primary_llm, backup_llm = self.select_primary_llm(business_objective, brand_tone, platform)
        
        # Construire le prompt pour Claude √† partir des messages OpenAI
        if system_message:
            full_prompt = f"System: {system_message}\n\n"
        else:
            full_prompt = ""
        
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            full_prompt += f"{role.capitalize()}: {content}\n\n"
        
        # Tentative 1: LLM primaire
        try:
            if primary_llm == "openai" and self.openai_client:
                logging.info(f"üöÄ Primary OpenAI (objective: {business_objective}, platform: {platform})...")
                
                response = self.openai_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                result = response.choices[0].message.content
                logging.info(f"‚úÖ OpenAI primary r√©ussi - {len(result)} chars")
                return result
                
            elif primary_llm == "claude" and self.claude_chat:
                logging.info(f"üß† Primary Claude (objective: {business_objective}, platform: {platform})...")
                
                user_message = UserMessage(text=full_prompt.strip())
                response = await self.claude_chat.send_message(user_message)
                
                logging.info(f"‚úÖ Claude primary r√©ussi - {len(response)} chars")
                return response
                
        except Exception as primary_error:
            logging.error(f"‚ùå Primary {primary_llm} √©chou√©: {primary_error}")
            print(f"‚ö†Ô∏è Primary {primary_llm} failed, trying {backup_llm} backup...")
        
        # Tentative 2: LLM backup
        try:
            if backup_llm == "openai" and self.openai_client:
                logging.info(f"üîÑ Backup OpenAI...")
                
                response = self.openai_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                result = response.choices[0].message.content
                logging.info(f"‚úÖ OpenAI backup r√©ussi - {len(result)} chars")
                print("‚úÖ OpenAI backup successful!")
                return result
                
            elif backup_llm == "claude" and self.claude_chat:
                logging.info(f"üîÑ Backup Claude...")
                
                user_message = UserMessage(text=full_prompt.strip())
                response = await self.claude_chat.send_message(user_message)
                
                logging.info(f"‚úÖ Claude backup r√©ussi - {len(response)} chars")
                print("‚úÖ Claude backup successful!")
                return response
                
        except Exception as backup_error:
            logging.error(f"‚ùå Backup {backup_llm} √©chou√©: {backup_error}")
            print(f"‚ùå Backup {backup_llm} failed: {str(backup_error)[:100]}...")
        
        # Si les deux √©chouent
        error_msg = f"Both {primary_llm} (primary) and {backup_llm} (backup) failed"
        logging.error(error_msg)
        raise Exception(error_msg)
    
    async def generate_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "gpt-4o",
        temperature: float = 0.7,
        max_tokens: int = 2000,
        system_message: Optional[str] = None
    ) -> str:
        """
        G√©n√®re une completion avec backup automatique (mode compatible ancien syst√®me)
        Essaie OpenAI d'abord, puis Claude en cas d'√©chec
        """
        return await self.generate_completion_with_strategy(
            messages=messages,
            business_objective="equilibre",  # D√©faut compatible
            brand_tone="professionnel",
            platform="instagram",
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            system_message=system_message
        )
    
    async def analyze_website_content(
        self,
        content_data: Dict[str, Any],
        website_url: str
    ) -> Dict[str, Any]:
        """Analyse de contenu web avec backup"""
        
        # Prompt ULTRA-APPROFONDI pour analyse maximale (sans changer la structure JSON)
        prompt = f"""
        Tu es un analyste expert en intelligence business et marketing digital. Ta mission : analyser ce site web de mani√®re EXHAUSTIVE pour extraire un MAXIMUM d'informations exploitables pour la cr√©ation de contenu marketing et posts sociaux.

        Analyse CHAQUE √©l√©ment du site en profondeur et r√©ponds UNIQUEMENT par un JSON structur√© avec les cl√©s suivantes:
        {{
            "analysis_summary": "Un r√©sum√© ULTRA-D√âTAILL√â de l'entreprise (400-600 mots) incluant : QUI ils sont exactement (nom, histoire, fondateurs), CE QU'ILS FONT en d√©tail (tous leurs produits/services avec sp√©cificit√©s), COMMENT ils le font (processus, m√©thodes, approche unique), leurs SP√âCIALIT√âS techniques, leur POSITIONNEMENT march√©, leurs VALEURS et mission, leur EXP√âRIENCE (ann√©es, r√©alisations, clients), leurs DIFF√âRENCIATEURS vs concurrence, leurs T√âMOIGNAGES clients si mentionn√©s, leurs TARIFS/PRIX si indiqu√©s, leur ZONE g√©ographique, leurs CERTIFICATIONS/PRIX, leurs √âQUIPES/EXPERTISE, tous les D√âTAILS exploitables pour cr√©er du contenu sp√©cifique",
            
            "key_topics": ["Extraire 8-12 sujets pr√©cis du site : tous les produits/services mentionn√©s, les domaines d'expertise, les mots-cl√©s r√©currents, les sp√©cialit√©s techniques, les valeurs/approches, les r√©sultats/r√©alisations, les processus uniques, etc."],
            
            "brand_tone": "Analyser finement le ton de communication avec nuances : professionnel/d√©contract√©/premium/accessible/expert/technique/√©motionnel/storytelling - √™tre pr√©cis sur le style exact utilis√©",
            
            "target_audience": "Description ULTRA-PR√âCISE du public cible en analysant tous les indices : √¢ge estim√©, profession/secteur, niveau de revenus sugg√©r√©, probl√©matiques adress√©es, motivations, comportements d'achat, canaux pr√©f√©r√©s, langage utilis√© pour s'adresser √† eux, exemples de clients mentionn√©s",
            
            "main_services": ["Lister TOUS les services/produits trouv√©s avec leurs sp√©cificit√©s exactes : 'Service X - processus Y - b√©n√©fice Z - cible W - prix P si mentionn√©', inclure tous les d√©tails trouv√©s : dur√©es, m√©thodologies, outils utilis√©s, livrables, garanties, etc."],
            
            "content_suggestions": ["G√©n√©rer 6-8 suggestions de posts TR√àS SP√âCIFIQUES bas√©es sur les √©l√©ments concrets trouv√©s : 'Post produit X avec caract√©ristique Y pour probl√®me Z', 'Post t√©moignage client A avec r√©sultat B', 'Post processus C avec √©tapes D-E-F', 'Post expertise G avec conseil H', 'Post coulisses I avec √©quipe J', 'Post r√©alisation K avec chiffres L', etc. - chaque suggestion doit √™tre exploitable imm√©diatement"]
        }}

        CONTENU DU SITE √Ä ANALYSER EN PROFONDEUR :
        
        URL du site: {website_url}
        Titre principal: {content_data.get('meta_title', 'Non d√©fini')}
        Description meta: {content_data.get('meta_description', 'Non d√©finie')}
        
        TOUS les titres H1 (tr√®s importants): {content_data.get('h1_tags', [])}
        TOUS les titres H2 (structure du contenu): {content_data.get('h2_tags', [])}
        
        CONTENU TEXTUEL COMPLET (√† analyser mot par mot):
        {content_data.get('text_content', 'Non disponible')[:4000]}
        
        PAGES ANALYS√âES: {len(content_data.get('pages_analyzed', []))} pages
        D√©tails des pages: {[page.get('title', 'Sans titre') + ' - ' + page.get('url', '') for page in content_data.get('pages_analyzed', [])[:10]]}

        INSTRUCTIONS ULTRA-SP√âCIFIQUES :
        
        üîç EXTRACTION MAXIMALE :
        - IDENTIFIE tous les produits/services avec noms exacts, caract√©ristiques, prix, processus
        - REL√àVE tous les t√©moignages, noms de clients, chiffres de r√©sultats, r√©alisations
        - D√âTECTE tous les mots-cl√©s m√©tier, jargon technique, termes sp√©cialis√©s
        - ANALYSE le vocabulaire pour identifier le niveau d'expertise et le public vis√©  
        - REP√àRE tous les √©l√©ments diff√©renciants, points forts, avantages concurrentiels
        - EXTRAIT les informations sur l'√©quipe, l'histoire, les valeurs, la mission
        - NOTE tous les d√©tails g√©ographiques, horaires, contacts, modalit√©s pratiques
        
        üí° PENS√âE MARKETING :
        - CHAQUE information extraite doit √™tre exploitable pour cr√©er un post sp√©cifique
        - PRIORISE les √©l√©ments qui peuvent g√©n√©rer de l'engagement social
        - IDENTIFIE les angles de contenu : expertise, coulisses, r√©sultats, processus, √©quipe
        - SUGG√àRE des posts concrets avec les √©l√©ments factuels trouv√©s
        
        üìä FACTUALIT√â TOTALE :
        - Utilise les TERMES EXACTS trouv√©s sur le site (pas de paraphrase)
        - CITE les chiffres, prix, dur√©es, noms pr√©cis mentionn√©s
        - BASE-toi uniquement sur ce qui est r√©ellement √©crit (pas d'invention)
        - STRUCTURE les informations de mani√®re exploitable pour le marketing
        
        OBJECTIF : Extraire suffisamment d'informations d√©taill√©es pour cr√©er 50+ posts diff√©rents et cibl√©s !
        """
        
        messages = [
            {
                "role": "system",
                "content": "Tu es un expert en analyse de contenu web et marketing digital. Tu analyses les sites web en profondeur pour cr√©er du contenu social media. R√©ponds UNIQUEMENT en JSON valide et structur√©."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        try:
            raw_response = await self.generate_completion(
                messages=messages,
                temperature=0.6,  # √âquilibre entre cr√©ativit√© et pr√©cision
                max_tokens=3500   # Plus de tokens pour des r√©ponses ultra-d√©taill√©es
            )
            
            # Parser la r√©ponse JSON
            if raw_response and len(raw_response) > 50:
                # Nettoyer la r√©ponse pour extraire le JSON
                clean_response = raw_response.strip()
                if clean_response.startswith('```json'):
                    clean_response = clean_response[7:]
                if clean_response.endswith('```'):
                    clean_response = clean_response[:-3]
                
                analysis_result = json.loads(clean_response.strip())
                
                # Valider que les cl√©s requises sont pr√©sentes
                required_keys = ['analysis_summary', 'key_topics', 'brand_tone', 'target_audience', 'main_services', 'content_suggestions']
                if all(key in analysis_result for key in required_keys):
                    logging.info("‚úÖ Analyse LLM backup r√©ussie")
                    return analysis_result
                else:
                    raise ValueError("Missing required keys in response")
            
            raise ValueError("Response too short or empty")
            
        except Exception as e:
            logging.error(f"‚ùå LLM backup analysis failed: {e}")
            # Fallback g√©n√©rique si tout √©choue
            return self._create_fallback_analysis(content_data, website_url)
    
    def _create_fallback_analysis(self, content_data: Dict[str, Any], website_url: str) -> Dict[str, Any]:
        """Analyse de fallback basique si tous les LLM √©chouent"""
        title = content_data.get('meta_title', website_url)
        
        return {
            "analysis_summary": f"Entreprise analys√©e : {title}. Analyse technique indisponible, veuillez r√©essayer.",
            "key_topics": ["entreprise", "services", "activit√©"],
            "brand_tone": "professionnel",
            "target_audience": "clients potentiels",
            "main_services": ["services principaux"],
            "content_suggestions": [
                "Pr√©senter l'entreprise",
                "Partager l'expertise",
                "Montrer les r√©alisations",
                "Communiquer avec les clients"
            ]
        }


# Instance globale du syst√®me de backup
llm_backup = LLMBackupSystem()
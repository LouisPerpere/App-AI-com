#!/usr/bin/env python3
"""
MIGRATION DIRECTE DES DONN√âES RESTAURANT
Script pour migrer directement les donn√©es depuis les notes vers les collections correctes
"""

import sys
import os
sys.path.append('/app/backend')
from database import get_database
import json
from datetime import datetime
import requests

TARGET_USER_ID = "82ce1284-ca2e-469a-8521-2a9116ef7826"
LIVE_BASE_URL = "https://claire-marcus.com/api"
TEST_EMAIL = "test@claire-marcus.com"
TEST_PASSWORD = "test123!"

def authenticate_api():
    """Authentifier via API"""
    try:
        session = requests.Session()
        response = session.post(f"{LIVE_BASE_URL}/auth/login-robust", json={
            "email": TEST_EMAIL,
            "password": TEST_PASSWORD
        })
        
        if response.status_code == 200:
            data = response.json()
            token = data.get('access_token')
            session.headers.update({'Authorization': f'Bearer {token}'})
            return session, token
        else:
            print(f"‚ùå Authentification √©chou√©e: {response.status_code}")
            return None, None
    except Exception as e:
        print(f"‚ùå Erreur authentification: {e}")
        return None, None

def get_notes_from_api():
    """R√©cup√©rer les notes via l'API"""
    session, token = authenticate_api()
    if not session:
        return []
    
    try:
        response = session.get(f"{LIVE_BASE_URL}/notes")
        if response.status_code == 200:
            data = response.json()
            return data.get('notes', [])
        else:
            print(f"‚ùå Erreur r√©cup√©ration notes: {response.status_code}")
            return []
    except Exception as e:
        print(f"‚ùå Erreur API notes: {e}")
        return []

def is_restaurant_post(content, description):
    """Identifier si une note est un post restaurant"""
    restaurant_keywords = [
        'bistrot', 'jean', 'facebook', 'instagram', 'menu', 'chef',
        'octobre_2024', 'novembre_2024', 'restaurant', 'cuisine',
        'hashtags', 'scheduled_date', 'platform', 'social_media_post'
    ]
    
    text = (content + ' ' + description).lower()
    return any(keyword in text for keyword in restaurant_keywords)

def is_website_analysis(content, description):
    """Identifier si une note est une analyse de site web"""
    analysis_keywords = [
        'lebistrotdejean', 'seo_score', 'website_analysis', 'performance',
        'accessibility', 'recommendations', 'https://lebistrotdejean-paris.fr'
    ]
    
    text = (content + ' ' + description).lower()
    return any(keyword in text for keyword in analysis_keywords)

def extract_post_from_note(note):
    """Extraire les donn√©es d'un post depuis une note"""
    try:
        content = note.get('content', '')
        description = note.get('description', '')
        note_id = note.get('note_id', '')
        
        # Essayer de parser le JSON du contenu
        if content.startswith('{') and content.endswith('}'):
            post_json = json.loads(content)
            
            # Cr√©er l'ID du post bas√© sur les donn√©es
            post_id = f"post_{TARGET_USER_ID}_{int(datetime.now().timestamp())}_{hash(note_id) % 1000}"
            
            # Transformer au format generated_posts
            return {
                'id': post_id,
                'owner_id': TARGET_USER_ID,
                'platform': post_json.get('platform', 'facebook'),
                'title': post_json.get('title', description or 'Post Restaurant'),
                'text': post_json.get('content', post_json.get('text', '')),
                'hashtags': post_json.get('hashtags', ['#bistrotdejean', '#restaurant']),
                'scheduled_date': post_json.get('scheduled_date', datetime.now().isoformat()),
                'status': post_json.get('status', 'ready'),
                'target_month': post_json.get('target_month', detect_target_month(content, description)),
                'created_at': datetime.now().isoformat(),
                'validated': False,
                'published': False,
                'visual_url': post_json.get('visual_url', ''),
                'visual_id': post_json.get('visual_id', ''),
                'content_type': 'restaurant',
                'migrated_from_note': note_id,
                'migration_date': datetime.now().isoformat()
            }
        else:
            # Format texte simple - cr√©er structure basique
            post_id = f"post_{TARGET_USER_ID}_{int(datetime.now().timestamp())}_{hash(content) % 1000}"
            
            return {
                'id': post_id,
                'owner_id': TARGET_USER_ID,
                'platform': 'facebook',
                'title': description or 'Post Restaurant',
                'text': content[:500],
                'hashtags': ['#bistrotdejean', '#restaurant'],
                'scheduled_date': datetime.now().isoformat(),
                'status': 'ready',
                'target_month': detect_target_month(content, description),
                'created_at': datetime.now().isoformat(),
                'validated': False,
                'published': False,
                'visual_url': '',
                'visual_id': '',
                'content_type': 'restaurant',
                'migrated_from_note': note_id,
                'migration_date': datetime.now().isoformat()
            }
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è Erreur extraction post: {e}")
        return None

def extract_analysis_from_note(note):
    """Extraire les donn√©es d'analyse depuis une note"""
    try:
        content = note.get('content', '')
        description = note.get('description', '')
        note_id = note.get('note_id', '')
        
        # Essayer de parser le JSON du contenu
        if content.startswith('{') and content.endswith('}'):
            analysis_json = json.loads(content)
            
            # Cr√©er l'ID de l'analyse
            analysis_id = f"analysis_{TARGET_USER_ID}_{int(datetime.now().timestamp())}_{hash(note_id) % 1000}"
            
            # Transformer au format website_analyses
            return {
                'id': analysis_id,
                'user_id': TARGET_USER_ID,
                'website_url': analysis_json.get('url', 'https://lebistrotdejean-paris.fr'),
                'seo_score': analysis_json.get('seo_score', 78),
                'performance_score': analysis_json.get('performance_score', 85),
                'accessibility_score': analysis_json.get('accessibility_score', 92),
                'overall_score': analysis_json.get('overall_score', 85.75),
                'recommendations': analysis_json.get('recommendations', []),
                'technical_analysis': analysis_json.get('technical_analysis', {}),
                'competitive_analysis': analysis_json.get('competitive_analysis', {}),
                'action_plan': analysis_json.get('action_plan', {}),
                'created_at': datetime.now().isoformat(),
                'status': 'completed',
                'migrated_from_note': note_id,
                'migration_date': datetime.now().isoformat()
            }
        else:
            # Format texte simple - cr√©er structure basique
            analysis_id = f"analysis_{TARGET_USER_ID}_{int(datetime.now().timestamp())}_{hash(content) % 1000}"
            
            return {
                'id': analysis_id,
                'user_id': TARGET_USER_ID,
                'website_url': 'https://lebistrotdejean-paris.fr',
                'seo_score': 78,
                'performance_score': 85,
                'accessibility_score': 92,
                'overall_score': 85.75,
                'recommendations': ['Optimisation des images', 'SEO local', 'Schema markup'],
                'technical_analysis': {'loading_speed': '3.2s', 'ssl_certificate': True},
                'competitive_analysis': {'position': '8-12', 'rating': '4.2/5'},
                'action_plan': {'phases': 4, 'priority': 'high'},
                'created_at': datetime.now().isoformat(),
                'status': 'completed',
                'migrated_from_note': note_id,
                'migration_date': datetime.now().isoformat()
            }
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è Erreur extraction analyse: {e}")
        return None

def detect_target_month(content, description):
    """D√©tecter le mois cible d'un post"""
    text = (content + ' ' + description).lower()
    
    if 'octobre' in text or 'october' in text:
        return 'octobre_2024'
    elif 'novembre' in text or 'november' in text:
        return 'novembre_2024'
    else:
        return 'octobre_2024'  # Par d√©faut

def run_direct_migration():
    """Ex√©cuter la migration directe"""
    print("=" * 80)
    print("üöÄ MIGRATION DIRECTE DES DONN√âES RESTAURANT")
    print("=" * 80)
    print(f"User ID cible: {TARGET_USER_ID}")
    print(f"Heure: {datetime.now().isoformat()}")
    print("=" * 80)
    
    # √âtape 1: R√©cup√©rer les notes via l'API
    print("üìù R√©cup√©ration des notes via API...")
    notes = get_notes_from_api()
    print(f"   Notes r√©cup√©r√©es: {len(notes)}")
    
    if not notes:
        print("‚ùå Aucune note r√©cup√©r√©e - migration interrompue")
        return False
    
    # √âtape 2: Analyser et cat√©goriser les notes
    restaurant_posts = []
    website_analyses = []
    
    for note in notes:
        content = note.get('content', '')
        description = note.get('description', '')
        
        if is_restaurant_post(content, description):
            restaurant_posts.append(note)
        elif is_website_analysis(content, description):
            website_analyses.append(note)
    
    print(f"   üçΩÔ∏è Posts restaurant identifi√©s: {len(restaurant_posts)}")
    print(f"   üîç Analyses site web identifi√©es: {len(website_analyses)}")
    
    # √âtape 3: Connexion √† la base de donn√©es
    db = get_database()
    
    # √âtape 4: Migrer les posts
    posts_migrated = 0
    posts_errors = []
    
    print(f"\nüì§ Migration des posts vers generated_posts...")
    for note in restaurant_posts:
        try:
            post_data = extract_post_from_note(note)
            
            if post_data:
                # V√©rifier si le post existe d√©j√†
                existing_post = db.db.generated_posts.find_one({
                    "migrated_from_note": note.get('note_id')
                })
                
                if not existing_post:
                    # Ins√©rer le post dans generated_posts
                    result = db.db.generated_posts.insert_one(post_data)
                    
                    if result.inserted_id:
                        posts_migrated += 1
                        print(f"   ‚úÖ Post migr√©: {post_data['title'][:50]}...")
                    else:
                        posts_errors.append(f"√âchec insertion: {post_data['title']}")
                else:
                    print(f"   ‚ö†Ô∏è Post d√©j√† existant: {post_data['title'][:50]}...")
            else:
                posts_errors.append(f"√âchec extraction: {note.get('description', 'N/A')}")
                
        except Exception as e:
            posts_errors.append(f"Erreur post {note.get('note_id', 'N/A')}: {str(e)}")
    
    # √âtape 5: Migrer les analyses
    analyses_migrated = 0
    analyses_errors = []
    
    print(f"\nüîç Migration des analyses vers website_analyses...")
    for note in website_analyses:
        try:
            analysis_data = extract_analysis_from_note(note)
            
            if analysis_data:
                # V√©rifier si l'analyse existe d√©j√†
                existing_analysis = db.db.website_analyses.find_one({
                    "migrated_from_note": note.get('note_id')
                })
                
                if not existing_analysis:
                    # Ins√©rer l'analyse dans website_analyses
                    result = db.db.website_analyses.insert_one(analysis_data)
                    
                    if result.inserted_id:
                        analyses_migrated += 1
                        print(f"   ‚úÖ Analyse migr√©e: {analysis_data['website_url']}")
                    else:
                        analyses_errors.append(f"√âchec insertion: {analysis_data['website_url']}")
                else:
                    print(f"   ‚ö†Ô∏è Analyse d√©j√† existante: {analysis_data['website_url']}")
            else:
                analyses_errors.append(f"√âchec extraction: {note.get('description', 'N/A')}")
                
        except Exception as e:
            analyses_errors.append(f"Erreur analyse {note.get('note_id', 'N/A')}: {str(e)}")
    
    # √âtape 6: V√©rifier le succ√®s via API
    print(f"\n‚úÖ V√©rification via API...")
    session, token = authenticate_api()
    
    if session:
        # Test GET /api/posts/generated
        try:
            response = session.get(f"{LIVE_BASE_URL}/posts/generated")
            if response.status_code == 200:
                api_posts = response.json().get('posts', [])
                print(f"   üìÑ Posts via API: {len(api_posts)}")
                
                if api_posts:
                    print(f"   ‚úÖ SUCC√àS: Posts maintenant visibles dans l'API!")
                    for i, post in enumerate(api_posts[:3]):
                        print(f"      {i+1}. {post.get('title', 'Sans titre')[:50]}...")
            else:
                print(f"   ‚ùå Erreur API posts: {response.status_code}")
        except Exception as e:
            print(f"   ‚ùå Erreur test API posts: {e}")
        
        # Test GET /api/website-analysis
        try:
            response = session.get(f"{LIVE_BASE_URL}/website-analysis")
            if response.status_code == 200:
                api_analyses = response.json().get('analyses', [])
                print(f"   üîç Analyses via API: {len(api_analyses)}")
                
                if api_analyses:
                    print(f"   ‚úÖ SUCC√àS: Analyses maintenant visibles dans l'API!")
            elif response.status_code == 404:
                print(f"   ‚ö†Ô∏è Endpoint /api/website-analysis n'existe pas encore")
            else:
                print(f"   ‚ùå Erreur API analyses: {response.status_code}")
        except Exception as e:
            print(f"   ‚ùå Erreur test API analyses: {e}")
    
    # R√©sum√© final
    print("\n" + "=" * 80)
    print("üéØ R√âSUM√â DE LA MIGRATION DIRECTE")
    print("=" * 80)
    
    print(f"üìä R√âSULTATS:")
    print(f"   Posts migr√©s: {posts_migrated}")
    print(f"   Analyses migr√©es: {analyses_migrated}")
    print(f"   Erreurs posts: {len(posts_errors)}")
    print(f"   Erreurs analyses: {len(analyses_errors)}")
    
    success = (posts_migrated > 0 or analyses_migrated > 0)
    
    if success:
        print(f"\n‚úÖ MIGRATION R√âUSSIE!")
        print(f"   Les donn√©es restaurant ont √©t√© migr√©es vers les bonnes collections")
        print(f"   L'interface utilisateur devrait maintenant afficher les posts et analyses")
    else:
        print(f"\n‚ö†Ô∏è MIGRATION √âCHOU√âE")
        if posts_errors or analyses_errors:
            print(f"   Des erreurs ont √©t√© rencontr√©es:")
            for error in (posts_errors + analyses_errors)[:5]:
                print(f"      - {error}")
    
    return success

if __name__ == "__main__":
    success = run_direct_migration()
    if success:
        print(f"\n‚úÖ MIGRATION DIRECTE TERMIN√âE AVEC SUCC√àS")
    else:
        print(f"\n‚ùå MIGRATION DIRECTE √âCHOU√âE")